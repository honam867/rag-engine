# Phase 1
SUPABASE_DB_URL=
SUPABASE_JWT_SECRET=

# Cloudflare R2
R2_ENDPOINT=
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET=

# Google Cloud Document AI (Phase 2)
GCP_PROJECT_ID=
GCP_LOCATION=us
DOCAI_OCR_PROCESSOR_ID=
GCP_CREDENTIALS_PATH=

# Phase 3 – RAG-Anything / LightRAG (RAG Engine)

# OpenAI-compatible LLM/embedding (dùng cho RAG-Anything / LightRAG – ingestion + retrieval)
OPENAI_API_KEY=
CONTEXT_WINDOW=2
MAX_CONTEXT_TOKENS=4000
# OPENAI_BASE_URL=https://api.openai.com/v1
REDIS_URL=redis://localhost:6379/0

# LightRAG Postgres / PGVector storage
# Mặc định, backend sẽ tự parse SUPABASE_DB_URL thành POSTGRES_* nếu các biến này KHÔNG được set.
# Nếu muốn override thủ công (hoặc dùng DB khác Supabase), hãy bỏ comment và điền giá trị phù hợp.
# POSTGRES_HOST=
# POSTGRES_PORT=5432
# POSTGRES_USER=
# POSTGRES_PASSWORD=
# POSTGRES_DATABASE=
# POSTGRES_MAX_CONNECTIONS=10
# POSTGRES_SSL_MODE=require

# Không cần set POSTGRES_WORKSPACE – app sẽ dùng workspace_id làm namespace cho LightRAG.

# Phase 8 – Answer Orchestrator (hộp đen trả lời)

# Model dùng để sinh câu trả lời (OpenAI-compatible chat model).
# Ví dụ: gpt-4.1-mini, gpt-4o-mini, gpt-4.1, ...
ANSWER_MODEL=gpt-4.1-mini

# API key cho hộp đen trả lời.
# Nếu không set ANSWER_API_KEY, backend sẽ tự dùng OPENAI_API_KEY ở trên.
# ANSWER_API_KEY=

# Base URL cho endpoint chat completions (OpenAI-compatible).
# Nếu dùng OpenAI chính thức, có thể để trống để mặc định là https://api.openai.com/v1
# hoặc reuse OPENAI_BASE_URL.
# ANSWER_BASE_URL=https://api.openai.com/v1

# Tuỳ chọn: override mặc định cho max tokens và temperature của câu trả lời.
# ANSWER_MAX_TOKENS=2048
# ANSWER_TEMPERATURE=0.2
